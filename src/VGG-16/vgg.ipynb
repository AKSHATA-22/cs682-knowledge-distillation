{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-30 13:09:22.855849: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-30 13:09:22.974228: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[22. 28.]\n",
      " [49. 64.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "    b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "    c = tf.matmul(a, b)\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "USE_GPU = True\n",
    "\n",
    "if USE_GPU and tf.config.list_physical_devices('GPU'):\n",
    "    device = 'GPU'\n",
    "    print(\"Using GPU\")\n",
    "else:\n",
    "    device = 'CPU'\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfds.core.DatasetInfo(\n",
      "    name='imagenet_resized',\n",
      "    full_name='imagenet_resized/64x64/0.1.0',\n",
      "    description=\"\"\"\n",
      "    This dataset consists of the ImageNet dataset resized to fixed size. The images\n",
      "    here are the ones provided by Chrabaszcz et. al. using the box resize method.\n",
      "    \n",
      "    For [downsampled ImageNet](http://image-net.org/download.php) for unsupervised\n",
      "    learning see `downsampled_imagenet`.\n",
      "    \n",
      "    WARNING: The integer labels used are defined by the authors and do not match\n",
      "    those from the other ImageNet datasets provided by Tensorflow datasets. See the\n",
      "    original\n",
      "    [label list](https://github.com/PatrykChrabaszcz/Imagenet32_Scripts/blob/master/map_clsloc.txt),\n",
      "    and the\n",
      "    [labels used by this dataset](https://github.com/tensorflow/datasets/blob/master/tensorflow_datasets/image_classification/imagenet_resized_labels.txt).\n",
      "    Additionally, the original authors 1 index there labels which we convert to 0\n",
      "    indexed by subtracting one.\n",
      "    \"\"\",\n",
      "    config_description=\"\"\"\n",
      "    Images resized to 64x64\n",
      "    \"\"\",\n",
      "    homepage='https://patrykchrabaszcz.github.io/Imagenet32/',\n",
      "    data_path='/home/asko/tensorflow_datasets/downloads/manual/imagenet_resized/64x64/0.1.0',\n",
      "    file_format=tfrecord,\n",
      "    download_size=13.13 GiB,\n",
      "    dataset_size=10.29 GiB,\n",
      "    features=FeaturesDict({\n",
      "        'image': Image(shape=(64, 64, 3), dtype=uint8),\n",
      "        'label': ClassLabel(shape=(), dtype=int64, num_classes=1000),\n",
      "    }),\n",
      "    supervised_keys=('image', 'label'),\n",
      "    disable_shuffling=False,\n",
      "    splits={\n",
      "        'train': <SplitInfo num_examples=1281167, num_shards=128>,\n",
      "        'validation': <SplitInfo num_examples=50000, num_shards=4>,\n",
      "    },\n",
      "    citation=\"\"\"@article{chrabaszcz2017downsampled,\n",
      "      title={A downsampled variant of imagenet as an alternative to the cifar datasets},\n",
      "      author={Chrabaszcz, Patryk and Loshchilov, Ilya and Hutter, Frank},\n",
      "      journal={arXiv preprint arXiv:1707.08819},\n",
      "      year={2017}\n",
      "    }\"\"\",\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Load the ImageNet dataset\n",
    "\n",
    "data_dir = '/home/asko/tensorflow_datasets/downloads/manual'\n",
    "\n",
    "# Load the ImageNet Resized dataset (e.g., 32x32)\n",
    "dataset, info = tfds.load('imagenet_resized/64x64', data_dir=data_dir, with_info=True, as_supervised=True)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_dataset = dataset['train']\n",
    "val_dataset = dataset['validation']\n",
    "\n",
    "# Print the dataset info\n",
    "print(info)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "# Load the VGG16 model pre-trained on ImageNet\n",
    "model = VGG16(weights='imagenet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.utils import load_img\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "\n",
    "# Load an example image and preprocess it\n",
    "img_path = '/home/asko/Documents/workspace/Fall-24/682/project/elephant.jpg'  # Replace with the path to your image\n",
    "img = load_img(img_path, target_size=(224, 224))\n",
    "x = img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "# Run the image through the model to obtain predictions\n",
    "predictions = model.predict(x)\n",
    "print(predictions.shape)\n",
    "print('Predicted:', decode_predictions(predictions, top=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "data_dir = '/home/asko/tensorflow_datasets/downloads/manual'\n",
    "dataset, info = tfds.load('imagenet_resized/64x64', data_dir=data_dir, with_info=True, as_supervised=True)\n",
    "\n",
    "train_dataset = dataset['train']\n",
    "val_dataset = dataset['validation']\n",
    "\n",
    "\n",
    "def preprocess(image, label):\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    image = preprocess_input(image) \n",
    "    return image, label\n",
    "\n",
    "batch_size = 32\n",
    "train_dataset = (train_dataset\n",
    "                 .map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "                 .shuffle(1000)  \n",
    "                 .batch(batch_size)\n",
    "                 .prefetch(tf.data.AUTOTUNE))\n",
    "\n",
    "val_dataset = (val_dataset\n",
    "               .map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "               .batch(batch_size)\n",
    "               .prefetch(tf.data.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F  # useful stateless functions\n",
    "\n",
    "dtype = torch.float32\n",
    "print_every = 100\n",
    "\n",
    "def train_part34(model, optimizer, epochs=1):\n",
    "    \n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(train_dataset):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            \n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "            if t % print_every == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "2 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "3 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "4 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "5 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "6 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "7 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "8 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "9 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "10 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "11 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "12 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "13 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "14 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "15 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "16 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "17 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "18 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "19 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "20 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "21 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "22 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "23 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "24 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "25 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "26 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "27 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "28 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "29 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "30 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "31 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "32 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "33 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "34 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "35 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "36 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "37 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "38 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "39 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "40 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "41 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "42 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "43 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "44 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "45 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "46 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "47 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "48 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "49 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "50 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "51 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "52 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "53 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "54 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "55 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "56 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "57 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "58 (32, 224, 224, 3) (32,)\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "59 (32, 224, 224, 3) (32,)\n"
     ]
    }
   ],
   "source": [
    "tf.device('/GPU:0' if device == 'GPU' else '/CPU:0')\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "output_file = 'predictions.csv'\n",
    "\n",
    "# Create CSV file and write headers if it doesn’t exist\n",
    "with open(output_file, mode='w') as f:\n",
    "    f.write(\"Prediction\\n\")\n",
    "\n",
    "for batch_idx, (images, labels) in enumerate(train_dataset):\n",
    "    print(batch_idx, images.shape, labels.shape)\n",
    "    predictions = model.predict(images)\n",
    "    batch_df = pd.DataFrame(predictions, columns=[f'Prediction_{i}' for i in range(predictions.shape[1])])\n",
    "    batch_df.to_csv(output_file, mode='a', header=False, index=False)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
