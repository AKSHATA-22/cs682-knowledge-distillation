{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "USE_GPU = True\n",
    "\n",
    "if USE_GPU and tf.config.list_physical_devices('GPU'):\n",
    "    device = 'GPU'\n",
    "    print(\"Using GPU\")\n",
    "else:\n",
    "    device = 'CPU'\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import random\n",
    "\n",
    "# Path to the downloaded tgz file\n",
    "tgz_path = \"/home/asko/Documents/workspace/Fall-24/682/project/dataset/imagenette2.tgz\"\n",
    "extract_path = \"./imagenette\"  # Target folder for extraction\n",
    "\n",
    "# Extract the file\n",
    "with tarfile.open(tgz_path, \"r:gz\") as tar:\n",
    "    tar.extractall(path=extract_path)\n",
    "print(\"Extraction completed.\")\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),  # Resize images to a size suitable for VGG16\n",
    "    transforms.ToTensor(),  # Convert image to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize as per VGG16\n",
    "])\n",
    "extract_path_train = \"./imagenette/imagenette2/train\"\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    root=extract_path_train,  # Imagenette URL\n",
    "    transform=transform\n",
    ")\n",
    "extract_path_val = \"./imagenette/imagenette2/val\"\n",
    "val_dataset = datasets.ImageFolder(\n",
    "    root=extract_path_val,  # Imagenette URL\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "batch_size = 8\n",
    "sampler_train = sampler.SubsetRandomSampler(range(len(train_dataset)))\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler_train)\n",
    "\n",
    "batch_size = 8\n",
    "sampler_val = sampler.SubsetRandomSampler(range(1000))\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, sampler=sampler_val)\n",
    "\n",
    "# batch_size = 16\n",
    "# sampler_test = sampler.SubsetRandomSampler(range(1000, len(val_dataset)))\n",
    "# test_loader = DataLoader(val_dataset, batch_size=batch_size, sampler=sampler_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from student.VGG_CMTKD_Student import VGG_CMTKD_Student\n",
    "from student.VGG_CMTKD_Teacher import VGG_CMTKD_Teacher\n",
    "from student.VGG_CMTKD_SuperTeacher import VGG_CMTKD_SuperTeacher\n",
    "from Teacher_vgg.TeacherCNN import TeacherCNN\n",
    "import torch\n",
    "\n",
    "alpha = 0.5\n",
    "beta  = 0.5\n",
    "temperature = 3\n",
    "pi1=0.6\n",
    "pi2=0.4\n",
    "bit_width = 2\n",
    "\n",
    "# Load the VGG16 model\n",
    "teacher_model = TeacherCNN(num_of_classes=10)\n",
    "# teacher_1_model = VGG_CMTKD_Teacher(bit_width=bit_width, num_of_classes=10, teacher_idx=1)\n",
    "# teacher_2_model = VGG_CMTKD_Teacher(bit_width=4, num_of_classes=10, teacher_idx=2)\n",
    "# teacher_1_model = VGG_CMTKD_SuperTeacher(bit_width1=6, bit_width2=4, num_of_classes=10, pi1=pi1, pi2=pi2)\n",
    "\n",
    "# student_model = VGG_CMTKD_Student(alpha=alpha, beta=beta, temperature=temperature, bit_width=2, pi1=pi1, pi2=pi2, num_of_classes=10)\n",
    "\n",
    "device = 'cuda' if len(tf.config.list_physical_devices('GPU'))!=0 else 'cpu'\n",
    "teacher_model.to(device)\n",
    "# teacher_2_model.to(device)\n",
    "# student_model.to(device)\n",
    "print(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy_part34(loader, model, model_name):\n",
    "    print(f'Checking accuracy on validation set for {model_name}')   \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=torch.float32)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model((x, False))\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "            # del preds, scores, _\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dill\n",
    "# with open(\"./cache/TeacherFP/model_1.pkl\", \"rb\") as f:\n",
    "#     teacher_model = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import dill\n",
    "\n",
    "teacher_1_optimizer = optim.Adam(teacher_model.parameters(), lr=0.01)\n",
    "torch.set_grad_enabled(True)\n",
    "\n",
    "num_epochs = 40\n",
    "# batch_size = 16  \n",
    "model_weights = None\n",
    "print_every = 100\n",
    "\n",
    "for epoch in range(num_epochs): \n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        teacher_model.train()     \n",
    "        # print('h1')\n",
    "        images = images.to(device, dtype=torch.float32)\n",
    "        labels = labels.to(device, dtype=torch.long)\n",
    "        \n",
    "        # print('h2')\n",
    "        teacher_output = teacher_model((images, False))\n",
    "        \n",
    "        # for k,_ in teacher_1_model.cache.items():\n",
    "        #     del teacher_1_model.cache[k]\n",
    "        # torch.save(teacher_model.cache, f'cache/TeacherFP/cache_{epoch}_{batch_idx}.pth')\n",
    "        # print(teacher_model.cache)\n",
    "        # teacher_model.cache.clear()\n",
    "        # teacher_1_model.cache.clear()\n",
    "        loss = F.cross_entropy(input=teacher_output, target=labels)\n",
    "        # print('h4')\n",
    "        \n",
    "        teacher_1_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        teacher_1_optimizer.step()\n",
    "            \n",
    "        if batch_idx % print_every == 0:\n",
    "            print('Iteration %d, loss = %.4f' % (batch_idx, loss.item()))\n",
    "            check_accuracy_part34(val_loader, teacher_model, \"teacher_1_model\")\n",
    "            print()\n",
    "            \n",
    "        torch.cuda.empty_cache()\n",
    "        del teacher_output, images, labels, loss\n",
    "    \n",
    "    with open(f'cache/TeacherFP/model_{epoch}.pkl', \"wb\") as f:\n",
    "        dill.dump(teacher_model, f)\n",
    "        \n",
    "    print(f\"Epoch {epoch} complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "import torch\n",
    "with open(\"./cache/TeacherFP/model_1\", \"rb\") as f:\n",
    "    teacher_model = dill.load(f)\n",
    "device = 'cuda' if len(tf.config.list_physical_devices('GPU'))!=0 else 'cpu'\n",
    "teacher_model.to(device)  \n",
    "print(teacher_model.cache)\n",
    "for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "    # print(len(teacher_model.cache))\n",
    "    # teacher_model.train()\n",
    "    \n",
    "    images = images.to(device, dtype=torch.float32)\n",
    "    output = teacher_model(images)\n",
    "    print(teacher_model.cache)\n",
    "    if batch_idx>2:\n",
    "        break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.optim as optim\n",
    "# import torch\n",
    "\n",
    "# student_optimizer = optim.Adam(student_model.parameters(), lr=0.01)\n",
    "# teacher_1_optimizer = optim.Adam(teacher_1_model.parameters(), lr=0.01)\n",
    "# teacher_2_optimizer = optim.Adam(teacher_2_model.parameters(), lr=0.01)\n",
    "# # optimizer = optim.SGD(student_model.parameters(), lr=0.01, weight_decay=1e-4, momentum=0.9, nesterov=True)\n",
    "# torch.set_grad_enabled(True)\n",
    "\n",
    "# num_epochs = 40\n",
    "# # batch_size = 16  \n",
    "# model_weights = None\n",
    "# print_every = 100\n",
    "\n",
    "# for epoch in range(num_epochs): \n",
    "#     for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "#         teacher_1_model.train()\n",
    "#         teacher_2_model.train()\n",
    "#         student_model.train()           \n",
    "#         # print('h1')\n",
    "#         images = images.to(device, dtype=torch.float32)\n",
    "#         labels = labels.to(device, dtype=torch.long)\n",
    "#         # print('h2')\n",
    "#         teacher_1_output = teacher_1_model(images)\n",
    "#         teacher_2_output = teacher_2_model(images)\n",
    "        \n",
    "#         student_output = student_model(images)\n",
    "#         # print('h3')\n",
    "#         loss = student_model.loss(labels=labels, teacher_1_output=teacher_1_output, teacher_2_output=teacher_2_output, student_output=student_output)\n",
    "#         # print('h4')\n",
    "#         student_optimizer.zero_grad()\n",
    "#         teacher_1_optimizer.zero_grad()\n",
    "#         teacher_2_optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         student_optimizer.step()\n",
    "#         teacher_1_optimizer.step()\n",
    "#         teacher_2_optimizer.step()\n",
    "            \n",
    "#         if batch_idx % print_every == 0:\n",
    "#             print('Iteration %d, loss = %.4f' % (batch_idx, loss.item()))\n",
    "#             check_accuracy_part34(val_loader, teacher_1_model, \"teacher_1_model\")\n",
    "#             check_accuracy_part34(val_loader, teacher_2_model, \"teacher_2_model\")\n",
    "#             check_accuracy_part34(val_loader, student_model, \"student_model\")\n",
    "#             print()\n",
    "            \n",
    "#         torch.cuda.empty_cache()\n",
    "#         del teacher_1_output, teacher_2_output, student_output, images, labels, loss\n",
    "        \n",
    "#     print(f\"Epoch {epoch} complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dill\n",
    "# with open(\"ta_model_retrained.pkl\", \"wb\") as f:\n",
    "#     dill.dump(ta_model, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
